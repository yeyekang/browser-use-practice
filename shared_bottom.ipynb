{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1kas1EzYpcmlUCea2leEoMz0diBaZBaXf",
      "authorship_tag": "ABX9TyMVNOE5soxLW5d7Zx+QbgLN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeyekang/Comparison-of-Multi-task-Models/blob/main/shared_bottom.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.datasets import fetch_openml\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.initializers import VarianceScaling\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "SEED = 1\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "\n",
        "# ==== 回调函数：输出ROC-AUC ====\n",
        "class ROCCallback(Callback):\n",
        "    def __init__(self, train, val, test):\n",
        "        self.train_X, self.train_Y = train\n",
        "        self.val_X, self.val_Y = val\n",
        "        self.test_X, self.test_Y = test\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        train_pred = self.model.predict(self.train_X, verbose=0)\n",
        "        val_pred = self.model.predict(self.val_X, verbose=0)\n",
        "        test_pred = self.model.predict(self.test_X, verbose=0)\n",
        "\n",
        "        for i, name in enumerate(self.model.output_names):\n",
        "            tr_auc = roc_auc_score(self.train_Y[i], train_pred[i])\n",
        "            va_auc = roc_auc_score(self.val_Y[i], val_pred[i])\n",
        "            te_auc = roc_auc_score(self.test_Y[i], test_pred[i])\n",
        "            print(f\"[Epoch {epoch+1}] {name} - AUC: Train={tr_auc:.4f}, Val={va_auc:.4f}, Test={te_auc:.4f}\")\n",
        "\n",
        "\n",
        "# ==== 数据准备 ====\n",
        "def data_preparation():\n",
        "    # 加载 Adult 数据集\n",
        "    data = fetch_openml(\"adult\", version=2, as_frame=True)\n",
        "    df = data.frame\n",
        "\n",
        "    # 特征 & 标签\n",
        "    X = pd.get_dummies(df.drop(columns=[\"class\", \"marital-status\"]))\n",
        "    y_income = (df[\"class\"] == \">50K\").astype(int).values\n",
        "    y_marital = (df[\"marital-status\"] == \"Never-married\").astype(int).values\n",
        "\n",
        "    # 划分 train/val/test (70/15/15)\n",
        "    n = len(X)\n",
        "    idx = np.arange(n)\n",
        "    np.random.shuffle(idx)\n",
        "    train_end, val_end = int(0.7 * n), int(0.85 * n)\n",
        "\n",
        "    train_idx = idx[:train_end]\n",
        "    val_idx = idx[train_end:val_end]\n",
        "    test_idx = idx[val_end:]\n",
        "\n",
        "    X_train = X.iloc[train_idx].values.astype(np.float32)\n",
        "    X_val = X.iloc[val_idx].values.astype(np.float32)\n",
        "    X_test = X.iloc[test_idx].values.astype(np.float32)\n",
        "\n",
        "    y_train = [to_categorical(y_income[train_idx]), to_categorical(y_marital[train_idx])]\n",
        "    y_val = [to_categorical(y_income[val_idx]), to_categorical(y_marital[val_idx])]\n",
        "    y_test = [to_categorical(y_income[test_idx]), to_categorical(y_marital[test_idx])]\n",
        "\n",
        "    output_info = [(2, \"income\"), (2, \"marital\")]\n",
        "\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test, output_info\n",
        "\n",
        "\n",
        "# ==== Shared-Bottom 模型 ====\n",
        "def build_shared_bottom(num_features, output_info):\n",
        "    inputs = Input(shape=(num_features,), name=\"input_layer\")\n",
        "\n",
        "    # shared-bottom 层\n",
        "    shared = Dense(64, activation=\"relu\", kernel_initializer=VarianceScaling())(inputs)\n",
        "    shared = Dense(32, activation=\"relu\", kernel_initializer=VarianceScaling())(shared)\n",
        "\n",
        "    outputs = []\n",
        "    for units, name in output_info:\n",
        "        tower = Dense(16, activation=\"relu\", kernel_initializer=VarianceScaling())(shared)\n",
        "        out = Dense(units, activation=\"softmax\", name=name, kernel_initializer=VarianceScaling())(tower)\n",
        "        outputs.append(out)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(\n",
        "    optimizer=Adam(),\n",
        "    loss={name: \"binary_crossentropy\" for _, name in output_info},\n",
        "    metrics={name: [\"accuracy\"] for _, name in output_info}\n",
        ")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# ==== 主函数 ====\n",
        "def main():\n",
        "    X_train, y_train, X_val, y_val, X_test, y_test, output_info = data_preparation()\n",
        "\n",
        "    print(\"Training data shape:\", X_train.shape)\n",
        "    print(\"Validation data shape:\", X_val.shape)\n",
        "    print(\"Test data shape:\", X_test.shape)\n",
        "\n",
        "    model = build_shared_bottom(X_train.shape[1], output_info)\n",
        "    model.summary()\n",
        "\n",
        "    model.fit(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=10,\n",
        "        callbacks=[ROCCallback((X_train, y_train), (X_val, y_val), (X_test, y_test))],\n",
        "        batch_size=128\n",
        "    )\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dwBrU8yljPB_",
        "outputId": "f3aac6b1-fd50-41a2-be6f-76a198696ea1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (34189, 98)\n",
            "Validation data shape: (7326, 98)\n",
            "Test data shape: (7327, 98)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m6,336\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │        \u001b[38;5;34m528\u001b[0m │ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │        \u001b[38;5;34m528\u001b[0m │ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ income (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │         \u001b[38;5;34m34\u001b[0m │ dense_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ marital (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │         \u001b[38;5;34m34\u001b[0m │ dense_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,336</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ income (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span> │ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ marital (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span> │ dense_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,540\u001b[0m (37.27 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,540</span> (37.27 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,540\u001b[0m (37.27 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,540</span> (37.27 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - income_accuracy: 0.6813 - income_loss: 332.8875 - loss: 461.4797 - marital_accuracy: 0.6256 - marital_loss: 128.5909[Epoch 1] income - AUC: Train=0.6081, Val=0.6009, Test=0.6106\n",
            "[Epoch 1] marital - AUC: Train=0.5118, Val=0.5109, Test=0.5136\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 40ms/step - income_accuracy: 0.6814 - income_loss: 332.0294 - loss: 460.3374 - marital_accuracy: 0.6255 - marital_loss: 128.3053 - val_income_accuracy: 0.7882 - val_income_loss: 19.0310 - val_loss: 31.2372 - val_marital_accuracy: 0.6706 - val_marital_loss: 12.3391\n",
            "Epoch 2/10\n",
            "\u001b[1m264/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - income_accuracy: 0.7315 - income_loss: 26.7723 - loss: 43.3204 - marital_accuracy: 0.5860 - marital_loss: 16.5481[Epoch 2] income - AUC: Train=0.5832, Val=0.5841, Test=0.5888\n",
            "[Epoch 2] marital - AUC: Train=0.5461, Val=0.5394, Test=0.5421\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - income_accuracy: 0.7313 - income_loss: 26.7924 - loss: 43.3431 - marital_accuracy: 0.5860 - marital_loss: 16.5511 - val_income_accuracy: 0.7882 - val_income_loss: 36.0892 - val_loss: 68.1580 - val_marital_accuracy: 0.3606 - val_marital_loss: 32.3289\n",
            "Epoch 3/10\n",
            "\u001b[1m263/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - income_accuracy: 0.7238 - income_loss: 29.7857 - loss: 45.9496 - marital_accuracy: 0.5824 - marital_loss: 16.1638[Epoch 3] income - AUC: Train=0.5885, Val=0.5885, Test=0.5937\n",
            "[Epoch 3] marital - AUC: Train=0.5131, Val=0.5130, Test=0.5144\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - income_accuracy: 0.7239 - income_loss: 29.7054 - loss: 45.8219 - marital_accuracy: 0.5826 - marital_loss: 16.1168 - val_income_accuracy: 0.7901 - val_income_loss: 27.7916 - val_loss: 55.1541 - val_marital_accuracy: 0.6706 - val_marital_loss: 27.5092\n",
            "Epoch 4/10\n",
            "\u001b[1m260/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - income_accuracy: 0.7226 - income_loss: 25.5951 - loss: 40.0372 - marital_accuracy: 0.6141 - marital_loss: 14.4420[Epoch 4] income - AUC: Train=0.5585, Val=0.5627, Test=0.5593\n",
            "[Epoch 4] marital - AUC: Train=0.5230, Val=0.5213, Test=0.5247\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - income_accuracy: 0.7225 - income_loss: 25.5183 - loss: 39.8952 - marital_accuracy: 0.6136 - marital_loss: 14.3771 - val_income_accuracy: 0.7820 - val_income_loss: 44.3851 - val_loss: 51.8292 - val_marital_accuracy: 0.6706 - val_marital_loss: 7.6201\n",
            "Epoch 5/10\n",
            "\u001b[1m266/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - income_accuracy: 0.7198 - income_loss: 20.9357 - loss: 29.4400 - marital_accuracy: 0.6024 - marital_loss: 8.5044[Epoch 5] income - AUC: Train=0.6365, Val=0.6348, Test=0.6381\n",
            "[Epoch 5] marital - AUC: Train=0.5392, Val=0.5359, Test=0.5411\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - income_accuracy: 0.7198 - income_loss: 20.8986 - loss: 29.4058 - marital_accuracy: 0.6023 - marital_loss: 8.5069 - val_income_accuracy: 0.7796 - val_income_loss: 6.2324 - val_loss: 11.6466 - val_marital_accuracy: 0.6706 - val_marital_loss: 5.4662\n",
            "Epoch 6/10\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - income_accuracy: 0.7113 - income_loss: 15.1209 - loss: 23.2505 - marital_accuracy: 0.6039 - marital_loss: 8.1296[Epoch 6] income - AUC: Train=0.5613, Val=0.5675, Test=0.5632\n",
            "[Epoch 6] marital - AUC: Train=0.7028, Val=0.6912, Test=0.7018\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - income_accuracy: 0.7113 - income_loss: 15.1270 - loss: 23.2590 - marital_accuracy: 0.6039 - marital_loss: 8.1320 - val_income_accuracy: 0.7815 - val_income_loss: 32.0656 - val_loss: 33.8650 - val_marital_accuracy: 0.6706 - val_marital_loss: 1.9517\n",
            "Epoch 7/10\n",
            "\u001b[1m264/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - income_accuracy: 0.7263 - income_loss: 20.4321 - loss: 30.2325 - marital_accuracy: 0.5982 - marital_loss: 9.8004[Epoch 7] income - AUC: Train=0.6147, Val=0.6135, Test=0.6188\n",
            "[Epoch 7] marital - AUC: Train=0.5717, Val=0.5646, Test=0.5726\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - income_accuracy: 0.7263 - income_loss: 20.3430 - loss: 30.1093 - marital_accuracy: 0.5982 - marital_loss: 9.7674 - val_income_accuracy: 0.7903 - val_income_loss: 11.0981 - val_loss: 18.9869 - val_marital_accuracy: 0.6704 - val_marital_loss: 7.9569\n",
            "Epoch 8/10\n",
            "\u001b[1m253/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - income_accuracy: 0.7354 - income_loss: 12.4190 - loss: 19.8495 - marital_accuracy: 0.5974 - marital_loss: 7.4306[Epoch 8] income - AUC: Train=0.5833, Val=0.5871, Test=0.5860\n",
            "[Epoch 8] marital - AUC: Train=0.6181, Val=0.6095, Test=0.6093\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - income_accuracy: 0.7345 - income_loss: 12.3350 - loss: 19.7481 - marital_accuracy: 0.5974 - marital_loss: 7.4129 - val_income_accuracy: 0.7847 - val_income_loss: 17.2788 - val_loss: 22.7618 - val_marital_accuracy: 0.4139 - val_marital_loss: 5.5822\n",
            "Epoch 9/10\n",
            "\u001b[1m265/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - income_accuracy: 0.7213 - income_loss: 8.9159 - loss: 13.6720 - marital_accuracy: 0.6050 - marital_loss: 4.7561[Epoch 9] income - AUC: Train=0.6047, Val=0.6071, Test=0.6103\n",
            "[Epoch 9] marital - AUC: Train=0.8132, Val=0.7967, Test=0.7981\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - income_accuracy: 0.7213 - income_loss: 8.9189 - loss: 13.6779 - marital_accuracy: 0.6051 - marital_loss: 4.7589 - val_income_accuracy: 0.7895 - val_income_loss: 11.5349 - val_loss: 13.3544 - val_marital_accuracy: 0.7711 - val_marital_loss: 1.8908\n",
            "Epoch 10/10\n",
            "\u001b[1m263/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - income_accuracy: 0.7410 - income_loss: 9.6293 - loss: 14.4791 - marital_accuracy: 0.6064 - marital_loss: 4.8498[Epoch 10] income - AUC: Train=0.6220, Val=0.6228, Test=0.6257\n",
            "[Epoch 10] marital - AUC: Train=0.5613, Val=0.5571, Test=0.5642\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - income_accuracy: 0.7408 - income_loss: 9.5979 - loss: 14.4384 - marital_accuracy: 0.6065 - marital_loss: 4.8407 - val_income_accuracy: 0.7917 - val_income_loss: 7.6098 - val_loss: 12.2234 - val_marital_accuracy: 0.6705 - val_marital_loss: 4.6543\n"
          ]
        }
      ]
    }
  ]
}